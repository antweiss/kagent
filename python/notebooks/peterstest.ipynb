{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=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\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Can you get the RED metrics for productpage from the default namespace? Also create a Grafana dashboard.\n",
      "---------- PlanningAgent ----------\n",
      "1. k8s_agent: Check if the productpage service, deployment, and pods are available in the default namespace using a command like:\n",
      "   \"kubectl get pods,deployments,services -n default | grep productpage\"\n",
      "\n",
      "2. prometheus_agent: After confirming that productpage is running, query the RED metrics for productpage. For example, use these Prometheus queries:\n",
      "   - Request Rate: \n",
      "     sum(rate(http_requests_total{namespace=\"default\", service=~\"productpage\"}[1m]))\n",
      "   - Error Rate: \n",
      "     sum(rate(http_requests_total{namespace=\"default\", service=~\"productpage\", code=~\"5..\"}[1m]))\n",
      "   - Duration (average): \n",
      "     sum(rate(http_request_duration_seconds_sum{namespace=\"default\", service=~\"productpage\"}[1m])) \n",
      "     /\n",
      "     sum(rate(http_request_duration_seconds_count{namespace=\"default\", service=~\"productpage\"}[1m]))\n",
      "\n",
      "3. grafana_agent: Create a Grafana dashboard for productpage that incorporates the above Prometheus queries. The dashboard should include panels for Request Rate, Error Rate, and Duration with clear labels and descriptions indicating they represent the RED metrics for productpage in the default namespace.\n",
      "\n",
      "TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Can you get the RED metrics for productpage from the default namespace? Also create a Grafana dashboard.', type='TextMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=602, completion_tokens=1164), content='1. k8s_agent: Check if the productpage service, deployment, and pods are available in the default namespace using a command like:\\n   \"kubectl get pods,deployments,services -n default | grep productpage\"\\n\\n2. prometheus_agent: After confirming that productpage is running, query the RED metrics for productpage. For example, use these Prometheus queries:\\n   - Request Rate: \\n     sum(rate(http_requests_total{namespace=\"default\", service=~\"productpage\"}[1m]))\\n   - Error Rate: \\n     sum(rate(http_requests_total{namespace=\"default\", service=~\"productpage\", code=~\"5..\"}[1m]))\\n   - Duration (average): \\n     sum(rate(http_request_duration_seconds_sum{namespace=\"default\", service=~\"productpage\"}[1m])) \\n     /\\n     sum(rate(http_request_duration_seconds_count{namespace=\"default\", service=~\"productpage\"}[1m]))\\n\\n3. grafana_agent: Create a Grafana dashboard for productpage that incorporates the above Prometheus queries. The dashboard should include panels for Request Rate, Error Rate, and Duration with clear labels and descriptions indicating they represent the RED metrics for productpage in the default namespace.\\n\\nTERMINATE', type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import SelectorGroupChat, RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.memory import ListMemory, MemoryContent, MemoryMimeType\n",
    "from kagent.tools import BuiltInTool\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"o3-mini\",\n",
    ")\n",
    "\n",
    "\n",
    "planning_agent = AssistantAgent(\n",
    "    \"PlanningAgent\",\n",
    "    description=\"An agent for planning tasks, this agent should be the first to engage when given a new task.\",\n",
    "    model_client=model_client,\n",
    "    system_message=f\"\"\"\n",
    "    You are a planning agent. Current date and time is: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "    Your job is to break down complex tasks into smaller, manageable subtasks that can be executed by the team members. If one task depends on another, make sure to assign the tasks in the correct order.\n",
    "\n",
    "    DO NOT MAKE UP ADDITIONAL AND UNNECESSARY SUBTASKS.\n",
    "\n",
    "    Your team members are:\n",
    "        k8s_agent: KNows how to interact with a Kubernetes cluster using the kubectl CLI. It can only run kubectl commands.\n",
    "        prometheus_agent: Knows how to query and retrieve metrics for services in the cluster.\n",
    "        grafana_agent: Knows how to generate Grafana dashboards from user input and Prometheus queries.\n",
    "\n",
    "    You only plan and delegate tasks - you do not execute them yourself. Always assign the task to the most appropriate team member.\n",
    "    \n",
    "    Create a program that represent the logic and order in which the agents have to run.\n",
    "\n",
    "    Tasks that explicitly require a specific tool or agent should be assigned to the agent with that tool. For example:\n",
    "    - if the task requires querying for metrics, it should be assigned to the Prometheus agent. Make sure the metric name is correct, for example \"http_requests_total\" instead of \"http_requests\".\n",
    "    - if the task requires to install Istio, it should be assigned to the Istio agent.\n",
    "    - if the task requires to generate a Grafana dashboard, it should be assigned to the Grafana agent.\n",
    "    - if the previous task fails and needs to be re-executed, it should be assigned to the same agent. If the task fails more than 5 times, respond with \"TERMINATE\".\n",
    "\n",
    "    When tasked to generate Grafana dashboards or Prometheus queries make sure you confirm the pods/services are available and running in the cluster.\n",
    "    The input for the grafana_agent should include the Prometheus query from the prometheus_agent as well as the description of the dashboard to create.\n",
    "\n",
    "    For example:\n",
    "    - if users asks for metrics from \"customers\" app, you will use the kubernetes agent to check for any services, deployments or pods that match the provided name. Then you'll use the fully qualified service or workload names when creating queries or dashboards.\n",
    "\n",
    "    Make sure you evaluate the tasks first before assigning them to the team members. For example, if the task requires querying metrics, you should first gather the information about the pods, services or namespaces that need to be queried.\n",
    "\n",
    "    When assigning tasks, use this format:\n",
    "    1. <agent>: <task>\n",
    "\n",
    "    After all tasks assigned to agents are complete, summarize the findings and end with \"TERMINATE\". DO NOT END THE CONVERSATION BEFORE ALL TASKS ARE COMPLETE.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "grafana_agent = AssistantAgent(\n",
    "    \"grafana_agent\",\n",
    "    description=\"An agent for Grafana operations\",\n",
    "    tools=[BuiltInTool(\"grafana.generate_dashboard_json\")],\n",
    "    model_client=model_client,\n",
    "    system_message=f\"\"\"You are a Grafana agent. You know how to interact with Grafana.\n",
    "    Current date and time is: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}.\n",
    "\n",
    "    The user input will contain the explanation of the dashboards to create and the Prometheus queries to use. Make sure you understand the requirements before creating the dashboard.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "prom_agent = AssistantAgent(\n",
    "    \"prometheus_agent\",\n",
    "    description=\"An agent for Prometheus operations\",\n",
    "    tools=[\n",
    "        BuiltInTool(\"prometheus.query\"),\n",
    "        BuiltInTool(\"prometheus.get_series\"),\n",
    "        BuiltInTool(\"prometheus.get_label_names\"),\n",
    "        BuiltInTool(\"prometheus.get_label_values\"),\n",
    "    ],\n",
    "    model_client=model_client,\n",
    "    system_message=f\"\"\"\n",
    "    You are a Prometheus agent. You know how to query metrics from Prometheus. Current date and time is: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}.\n",
    "    For any time related queries, always use the current time as the reference. If the time range is not provided in the task, use the past 24 hours as time range.\n",
    "\n",
    "    # Input\n",
    "    You'll receive the user query describing which metrics to retrieve or queries to generate. Make sure you validate the metric names before creating a query.\n",
    "\n",
    "    # Tips\n",
    "    Always check all relevant metrics (error rate, latency, responses). If Istio is installed, check metrics with the following prefixes:\n",
    "    - envoy_\n",
    "    - istio_requests_total\n",
    "    - istio_request_duration_milliseconds\n",
    "\n",
    "    # Output\n",
    "    The output should contain ALL information necessary to construct dashboards:\n",
    "    - full query\n",
    "    - metric names\n",
    "    - metric values\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "k8s_agent = AssistantAgent(\n",
    "    \"k8s_agent\",\n",
    "    description=\"An agent for k8s operations\",\n",
    "    tools=[BuiltInTool(\"k8s.get_resources\")],\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a Kubernetes agent. You know how to interact with a Kubernetes cluster.\n",
    "\n",
    "    # Tips\n",
    "    - when asked to get the pods, make sure you check the deployment first and then get the pods that belong to that deployment.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "text_mention_termination = TextMentionTermination(\"TERMINATE\")\n",
    "max_messages_termination = MaxMessageTermination(max_messages=20)\n",
    "termination = text_mention_termination | max_messages_termination\n",
    "\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    [planning_agent, k8s_agent, prom_agent, grafana_agent],\n",
    "    termination_condition=termination\n",
    ")\n",
    "\n",
    "task =\"Can you get the RED metrics for productpage from the default namespace? Also create a Grafana dashboard.\"\n",
    "# Use asyncio.run(...) if you are running this in a script.\n",
    "await Console(team.run_stream(task=task))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"provider\": \"autogen_agentchat.teams.RoundRobinGroupChat\",\n",
      "  \"component_type\": \"team\",\n",
      "  \"version\": 1,\n",
      "  \"component_version\": 1,\n",
      "  \"description\": \"A team that runs a group chat with participants taking turns in a round-robin fashion\\n    to publish a message to all.\",\n",
      "  \"label\": \"RoundRobinGroupChat\",\n",
      "  \"config\": {\n",
      "    \"participants\": [\n",
      "      {\n",
      "        \"provider\": \"autogen_agentchat.agents.AssistantAgent\",\n",
      "        \"component_type\": \"agent\",\n",
      "        \"version\": 1,\n",
      "        \"component_version\": 1,\n",
      "        \"description\": \"An agent that provides assistance with tool use.\",\n",
      "        \"label\": \"AssistantAgent\",\n",
      "        \"config\": {\n",
      "          \"name\": \"PlanningAgent\",\n",
      "          \"model_client\": {\n",
      "            \"provider\": \"autogen_ext.models.openai.OpenAIChatCompletionClient\",\n",
      "            \"component_type\": \"model\",\n",
      "            \"version\": 1,\n",
      "            \"component_version\": 1,\n",
      "            \"description\": \"Chat completion client for OpenAI hosted models.\",\n",
      "            \"label\": \"OpenAIChatCompletionClient\",\n",
      "            \"config\": {\n",
      "              \"model\": \"o3-mini\"\n",
      "            }\n",
      "          },\n",
      "          \"tools\": [],\n",
      "          \"handoffs\": [],\n",
      "          \"model_context\": {\n",
      "            \"provider\": \"autogen_core.model_context.UnboundedChatCompletionContext\",\n",
      "            \"component_type\": \"chat_completion_context\",\n",
      "            \"version\": 1,\n",
      "            \"component_version\": 1,\n",
      "            \"description\": \"An unbounded chat completion context that keeps a view of the all the messages.\",\n",
      "            \"label\": \"UnboundedChatCompletionContext\",\n",
      "            \"config\": {}\n",
      "          },\n",
      "          \"description\": \"An agent for planning tasks, this agent should be the first to engage when given a new task.\",\n",
      "          \"system_message\": \"\\n    You are a planning agent. Current date and time is: 2025-02-05 22:45:14\\n    Your job is to break down complex tasks into smaller, manageable subtasks that can be executed by the team members. If one task depends on another, make sure to assign the tasks in the correct order.\\n\\n    DO NOT MAKE UP ADDITIONAL AND UNNECESSARY SUBTASKS.\\n\\n    Your team members are:\\n        k8s_agent: KNows how to interact with a Kubernetes cluster using the kubectl CLI. It can only run kubectl commands.\\n        prometheus_agent: Knows how to query and retrieve metrics for services in the cluster.\\n        grafana_agent: Knows how to generate Grafana dashboards from user input and Prometheus queries.\\n\\n    You only plan and delegate tasks - you do not execute them yourself. Always assign the task to the most appropriate team member.\\n\\n    Tasks that explicitly require a specific tool or agent should be assigned to the agent with that tool. For example:\\n    - if the task requires querying for metrics, it should be assigned to the Prometheus agent. Make sure the metric name is correct, for example \\\"http_requests_total\\\" instead of \\\"http_requests\\\".\\n    - if the task requires to install Istio, it should be assigned to the Istio agent.\\n    - if the task requires to generate a Grafana dashboard, it should be assigned to the Grafana agent.\\n    - if the previous task fails and needs to be re-executed, it should be assigned to the same agent. If the task fails more than 5 times, respond with \\\"TERMINATE\\\".\\n\\n    When tasked to generate Grafana dashboards or Prometheus queries make sure you confirm the pods/services are available and running in the cluster.\\n    The input for the grafana_agent should include the Prometheus query from the prometheus_agent as well as the description of the dashboard to create.\\n\\n    For example:\\n    - if users asks for metrics from \\\"customers\\\" app, you will use the kubernetes agent to check for any services, deployments or pods that match the provided name. Then you'll use the fully qualified service or workload names when creating queries or dashboards.\\n\\n    Make sure you evaluate the tasks first before assigning them to the team members. For example, if the task requires querying metrics, you should first gather the information about the pods, services or namespaces that need to be queried.\\n\\n    When assigning tasks, use this format:\\n    1. <agent>: <task>\\n\\n    After all tasks assigned to agents are complete, summarize the findings and end with \\\"TERMINATE\\\". DO NOT END THE CONVERSATION BEFORE ALL TASKS ARE COMPLETE.\\n    \",\n",
      "          \"model_client_stream\": false,\n",
      "          \"reflect_on_tool_use\": false,\n",
      "          \"tool_call_summary_format\": \"{result}\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"provider\": \"autogen_agentchat.agents.AssistantAgent\",\n",
      "        \"component_type\": \"agent\",\n",
      "        \"version\": 1,\n",
      "        \"component_version\": 1,\n",
      "        \"description\": \"An agent that provides assistance with tool use.\",\n",
      "        \"label\": \"AssistantAgent\",\n",
      "        \"config\": {\n",
      "          \"name\": \"k8s_agent\",\n",
      "          \"model_client\": {\n",
      "            \"provider\": \"autogen_ext.models.openai.OpenAIChatCompletionClient\",\n",
      "            \"component_type\": \"model\",\n",
      "            \"version\": 1,\n",
      "            \"component_version\": 1,\n",
      "            \"description\": \"Chat completion client for OpenAI hosted models.\",\n",
      "            \"label\": \"OpenAIChatCompletionClient\",\n",
      "            \"config\": {\n",
      "              \"model\": \"o3-mini\"\n",
      "            }\n",
      "          },\n",
      "          \"tools\": [\n",
      "            {\n",
      "              \"provider\": \"kagent.tools.BuiltInTool\",\n",
      "              \"component_type\": \"tool\",\n",
      "              \"version\": 1,\n",
      "              \"component_version\": 1,\n",
      "              \"label\": \"BuiltInTool\",\n",
      "              \"config\": {\n",
      "                \"fn_name\": \"k8s.get_resources\"\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"handoffs\": [],\n",
      "          \"model_context\": {\n",
      "            \"provider\": \"autogen_core.model_context.UnboundedChatCompletionContext\",\n",
      "            \"component_type\": \"chat_completion_context\",\n",
      "            \"version\": 1,\n",
      "            \"component_version\": 1,\n",
      "            \"description\": \"An unbounded chat completion context that keeps a view of the all the messages.\",\n",
      "            \"label\": \"UnboundedChatCompletionContext\",\n",
      "            \"config\": {}\n",
      "          },\n",
      "          \"description\": \"An agent for k8s operations\",\n",
      "          \"system_message\": \"\\n    You are a Kubernetes agent. You know how to interact with a Kubernetes cluster.\\n\\n    # Tips\\n    - when asked to get the pods, make sure you check the deployment first and then get the pods that belong to that deployment.\\n    \",\n",
      "          \"model_client_stream\": false,\n",
      "          \"reflect_on_tool_use\": false,\n",
      "          \"tool_call_summary_format\": \"{result}\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"provider\": \"autogen_agentchat.agents.AssistantAgent\",\n",
      "        \"component_type\": \"agent\",\n",
      "        \"version\": 1,\n",
      "        \"component_version\": 1,\n",
      "        \"description\": \"An agent that provides assistance with tool use.\",\n",
      "        \"label\": \"AssistantAgent\",\n",
      "        \"config\": {\n",
      "          \"name\": \"prometheus_agent\",\n",
      "          \"model_client\": {\n",
      "            \"provider\": \"autogen_ext.models.openai.OpenAIChatCompletionClient\",\n",
      "            \"component_type\": \"model\",\n",
      "            \"version\": 1,\n",
      "            \"component_version\": 1,\n",
      "            \"description\": \"Chat completion client for OpenAI hosted models.\",\n",
      "            \"label\": \"OpenAIChatCompletionClient\",\n",
      "            \"config\": {\n",
      "              \"model\": \"o3-mini\"\n",
      "            }\n",
      "          },\n",
      "          \"tools\": [\n",
      "            {\n",
      "              \"provider\": \"kagent.tools.BuiltInTool\",\n",
      "              \"component_type\": \"tool\",\n",
      "              \"version\": 1,\n",
      "              \"component_version\": 1,\n",
      "              \"label\": \"BuiltInTool\",\n",
      "              \"config\": {\n",
      "                \"fn_name\": \"prometheus.query\"\n",
      "              }\n",
      "            },\n",
      "            {\n",
      "              \"provider\": \"kagent.tools.BuiltInTool\",\n",
      "              \"component_type\": \"tool\",\n",
      "              \"version\": 1,\n",
      "              \"component_version\": 1,\n",
      "              \"label\": \"BuiltInTool\",\n",
      "              \"config\": {\n",
      "                \"fn_name\": \"prometheus.get_series\"\n",
      "              }\n",
      "            },\n",
      "            {\n",
      "              \"provider\": \"kagent.tools.BuiltInTool\",\n",
      "              \"component_type\": \"tool\",\n",
      "              \"version\": 1,\n",
      "              \"component_version\": 1,\n",
      "              \"label\": \"BuiltInTool\",\n",
      "              \"config\": {\n",
      "                \"fn_name\": \"prometheus.get_label_names\"\n",
      "              }\n",
      "            },\n",
      "            {\n",
      "              \"provider\": \"kagent.tools.BuiltInTool\",\n",
      "              \"component_type\": \"tool\",\n",
      "              \"version\": 1,\n",
      "              \"component_version\": 1,\n",
      "              \"label\": \"BuiltInTool\",\n",
      "              \"config\": {\n",
      "                \"fn_name\": \"prometheus.get_label_values\"\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"handoffs\": [],\n",
      "          \"model_context\": {\n",
      "            \"provider\": \"autogen_core.model_context.UnboundedChatCompletionContext\",\n",
      "            \"component_type\": \"chat_completion_context\",\n",
      "            \"version\": 1,\n",
      "            \"component_version\": 1,\n",
      "            \"description\": \"An unbounded chat completion context that keeps a view of the all the messages.\",\n",
      "            \"label\": \"UnboundedChatCompletionContext\",\n",
      "            \"config\": {}\n",
      "          },\n",
      "          \"description\": \"An agent for Prometheus operations\",\n",
      "          \"system_message\": \"\\n    You are a Prometheus agent. You know how to query metrics from Prometheus. Current date and time is: 2025-02-05 22:45:14.\\n    For any time related queries, always use the current time as the reference. If the time range is not provided in the task, use the past 24 hours as time range.\\n\\n    # Input\\n    You'll receive the user query describing which metrics to retrieve or queries to generate. Make sure you validate the metric names before creating a query.\\n\\n    # Tips\\n    Always check all relevant metrics (error rate, latency, responses). If Istio is installed, check metrics with the following prefixes:\\n    - envoy_\\n    - istio_requests_total\\n    - istio_request_duration_milliseconds\\n\\n    # Output\\n    The output should contain ALL information necessary to construct dashboards:\\n    - full query\\n    - metric names\\n    - metric values\\n    \",\n",
      "          \"model_client_stream\": false,\n",
      "          \"reflect_on_tool_use\": false,\n",
      "          \"tool_call_summary_format\": \"{result}\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"provider\": \"autogen_agentchat.agents.AssistantAgent\",\n",
      "        \"component_type\": \"agent\",\n",
      "        \"version\": 1,\n",
      "        \"component_version\": 1,\n",
      "        \"description\": \"An agent that provides assistance with tool use.\",\n",
      "        \"label\": \"AssistantAgent\",\n",
      "        \"config\": {\n",
      "          \"name\": \"grafana_agent\",\n",
      "          \"model_client\": {\n",
      "            \"provider\": \"autogen_ext.models.openai.OpenAIChatCompletionClient\",\n",
      "            \"component_type\": \"model\",\n",
      "            \"version\": 1,\n",
      "            \"component_version\": 1,\n",
      "            \"description\": \"Chat completion client for OpenAI hosted models.\",\n",
      "            \"label\": \"OpenAIChatCompletionClient\",\n",
      "            \"config\": {\n",
      "              \"model\": \"o3-mini\"\n",
      "            }\n",
      "          },\n",
      "          \"tools\": [\n",
      "            {\n",
      "              \"provider\": \"kagent.tools.BuiltInTool\",\n",
      "              \"component_type\": \"tool\",\n",
      "              \"version\": 1,\n",
      "              \"component_version\": 1,\n",
      "              \"label\": \"BuiltInTool\",\n",
      "              \"config\": {\n",
      "                \"fn_name\": \"grafana.generate_dashboard_json\"\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"handoffs\": [],\n",
      "          \"model_context\": {\n",
      "            \"provider\": \"autogen_core.model_context.UnboundedChatCompletionContext\",\n",
      "            \"component_type\": \"chat_completion_context\",\n",
      "            \"version\": 1,\n",
      "            \"component_version\": 1,\n",
      "            \"description\": \"An unbounded chat completion context that keeps a view of the all the messages.\",\n",
      "            \"label\": \"UnboundedChatCompletionContext\",\n",
      "            \"config\": {}\n",
      "          },\n",
      "          \"description\": \"An agent for Grafana operations\",\n",
      "          \"system_message\": \"You are a Grafana agent. You know how to interact with Grafana.\\n    Current date and time is: 2025-02-05 22:45:14.\\n\\n    The user input will contain the explanation of the dashboards to create and the Prometheus queries to use. Make sure you understand the requirements before creating the dashboard.\\n    \",\n",
      "          \"model_client_stream\": false,\n",
      "          \"reflect_on_tool_use\": false,\n",
      "          \"tool_call_summary_format\": \"{result}\"\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"termination_condition\": {\n",
      "      \"provider\": \"autogen_agentchat.base.OrTerminationCondition\",\n",
      "      \"component_type\": \"termination\",\n",
      "      \"version\": 1,\n",
      "      \"component_version\": 1,\n",
      "      \"label\": \"OrTerminationCondition\",\n",
      "      \"config\": {\n",
      "        \"conditions\": [\n",
      "          {\n",
      "            \"provider\": \"autogen_agentchat.conditions.TextMentionTermination\",\n",
      "            \"component_type\": \"termination\",\n",
      "            \"version\": 1,\n",
      "            \"component_version\": 1,\n",
      "            \"description\": \"Terminate the conversation if a specific text is mentioned.\",\n",
      "            \"label\": \"TextMentionTermination\",\n",
      "            \"config\": {\n",
      "              \"text\": \"TERMINATE\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"provider\": \"autogen_agentchat.conditions.MaxMessageTermination\",\n",
      "            \"component_type\": \"termination\",\n",
      "            \"version\": 1,\n",
      "            \"component_version\": 1,\n",
      "            \"description\": \"Terminate the conversation after a maximum number of messages have been exchanged.\",\n",
      "            \"label\": \"MaxMessageTermination\",\n",
      "            \"config\": {\n",
      "              \"max_messages\": 20\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(team.dump_component().model_dump_json(indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
